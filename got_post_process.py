#!/usr/bin/env python3
"""Perl-exact GoT post-process (linear mode)

This script is a line-by-line translation of the Perl post_process()
logic from IronThrone-GoT for the *linear* run mode.

It consumes a *.looked file produced by the Perl pre-process and outputs:
  - <sample>.summTable.txt

If --keepouts 1, it also writes Perl-style intermediate tables:
  - <sample>.MTX_changed.txt
  - <sample>.MTX_RE.dedup.txt
  - <sample>.MTX_MERGE.txt

Notes on exactness:
- Implements the same rescue logic (Hamming distance <=1 with posterior cutoff).
- Implements the same dedup selection logic (including the subtle Perl behavior
  where WT-majority chooses min BQ.in.WT across *all* reads in the UMI group).
- Implements the same cell-level counting logic (Perl counts using a temporary
  mismatch.call computed from mismatch.WT/mismatch.MUT; it does not overwrite
  call.in.dups).

Author: generated by ChatGPT
"""

from __future__ import annotations

import argparse
import math
import os
from collections import Counter
from typing import Dict, Iterable, List, Sequence, Tuple


# ----------------------------
# Small utilities (Perl-like)
# ----------------------------

def perl_round_to_int(x: float) -> int:
    """Match Perl's sprintf('%.0f', x) rounding (banker's rounding)."""
    # Python's round() uses bankers rounding for .5 ties, matching Perl's sprintf.
    return int(round(x))


def first_diff_pos_1(a: str, b: str) -> int:
    """Return the first position where a and b differ.

    Perl's str_diff_pos_1 returns the index (0-based) of the differing position
    when two strings differ by exactly 1 mismatch. We assume that's true here.
    """
    la = len(a)
    lb = len(b)
    n = la if la < lb else lb
    for i in range(n):
        if a[i] != b[i]:
            return i
    # If identical (shouldn't happen in rescue), return 0.
    return 0


def bcq_at_pos(bc_q: str, pos: int) -> float:
    """Get the barcode phred score at 0-based position `pos`.

    Perl stores BC_Q as '40;40;...;40;' (often trailing ';').
    In Perl, split(';', $str) will include a trailing empty entry.

    If the value is missing/non-numeric, Perl numeric context tends to treat
    it as 0. We mimic that behavior by returning 0.0.
    """
    parts = bc_q.split(";")
    if pos < 0 or pos >= len(parts):
        return 0.0
    raw = parts[pos].strip()
    if raw == "":
        return 0.0
    try:
        return float(raw)
    except ValueError:
        return 0.0


def sum_bcq(bc_q: str) -> float:
    """Perl-like sum of semicolon-delimited BC_Q numeric values."""
    total = 0.0
    for p in bc_q.split(";"):
        p = p.strip()
        if not p:
            continue
        try:
            total += float(p)
        except ValueError:
            # Perl would treat non-numeric as 0 in numeric context.
            continue
    return total


def write_tsv(path: str, header: Sequence[str], rows: Iterable[Sequence[str]]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write("\t".join(header) + "\n")
        for r in rows:
            f.write("\t".join(map(str, r)) + "\n")


# ----------------------------
# Readers
# ----------------------------

def read_config_linear(config_path: str) -> Tuple[str, str, str]:
    """Return (primer_seq, general_seq, wt_seq) from the config.

    Matches Perl post_process() usage:
      primer_seq = first column of line 1
      general_seq = first column of line 2
      wt_seq     = first column of line 3
    """
    with open(config_path, "r", encoding="utf-8") as f:
        lines = [ln.rstrip("\n") for ln in f if ln.strip()]

    if len(lines) < 3:
        raise ValueError(f"Config file {config_path} has < 3 non-empty lines")

    primer_seq = lines[0].split("\t")[0]
    general_seq = lines[1].split("\t")[0]
    wt_seq = lines[2].split("\t")[0]
    return primer_seq, general_seq, wt_seq


def read_whitelist_with_order(whitelist_path: str) -> Dict[str, int]:
    """Read whitelist as a dict bc->order_index (0-based)."""
    wl_idx: Dict[str, int] = {}
    with open(whitelist_path, "r", encoding="utf-8") as f:
        i = 0
        for ln in f:
            bc = ln.strip()
            if not bc:
                continue
            # Keep first occurrence order (Perl unique() keeps first occurrence)
            if bc not in wl_idx:
                wl_idx[bc] = i
                i += 1
    return wl_idx


def read_looked_linear(looked_path: str) -> List[List[str]]:
    """Read the Perl *.looked file (linear mode) into a list of rows.

    Each row is a list of 12 strings in this order:
      0 BC
      1 BC_Q
      2 UMI
      3 mismatch.primer
      4 mismatch.shared
      5 mismatch.WT
      6 mismatch.MUT
      7 avg.base_error.R2
      8 avg.base_error.primer
      9 avg.base_error.shared
     10 avg.base_error.WT
     11 avg.base_error.MUT

    The Perl *.looked file usually has *no header*.
    """
    rows: List[List[str]] = []
    with open(looked_path, "r", encoding="utf-8") as f:
        for ln in f:
            ln = ln.rstrip("\n")
            if not ln:
                continue
            parts = ln.split("\t")
            if parts[0] == "BC":
                # In case someone added a header.
                continue
            if len(parts) < 12:
                # Skip malformed lines.
                continue
            rows.append(parts[:12])
    return rows


# ----------------------------
# Rescue candidates (Hamm<=1)
# ----------------------------

def hamm1_candidates(obs_bc: str, wl_idx: Dict[str, int], charset: str = "ACGTN") -> List[str]:
    """Return whitelist barcodes within Hamming distance 1 of obs_bc.

    To match Perl's stringdist_hamm(), we return candidates ordered by
    whitelist order.

    Note: obs_bc is assumed NOT to be in whitelist (we only call for non-WL).
    """
    L = len(obs_bc)
    found = {}
    for i in range(L):
        orig = obs_bc[i]
        for c in charset:
            if c == orig:
                continue
            nb = obs_bc[:i] + c + obs_bc[i + 1 :]
            idx = wl_idx.get(nb)
            if idx is not None:
                # Use dict to deduplicate while keeping the earliest index.
                if nb not in found or idx < found[nb]:
                    found[nb] = idx

    # Sort by whitelist index (Perl loops whitelist in file order)
    return [bc for bc, _ in sorted(found.items(), key=lambda kv: kv[1])]


# ----------------------------
# Main post-process (linear)
# ----------------------------

def post_process_linear(
    looked_rows: List[List[str]],
    wl_idx: Dict[str, int],
    primer_alw: int,
    general_alw: int,
    wt_alw: int,
    postp_cut: float,
    dupcut: int,
    keepouts: int,
    outdir: str,
    sample: str,
    verbose: int,
) -> str:
    """Run the Perl-equivalent post_process for linear mode.

    Returns the path to the generated summTable.
    """

    def log(msg: str) -> None:
        if verbose:
            print(msg, flush=True)

    # ----------------------------
    # 1) Filter primed reads
    # ----------------------------
    primed: List[List[str]] = []
    for r in looked_rows:
        try:
            mm_primer = int(r[3])
            mm_shared = int(r[4])
        except ValueError:
            continue
        if mm_primer <= primer_alw and mm_shared <= general_alw:
            primed.append(r)

    log(f"[post] primed rows: {len(primed)}")

    # ----------------------------
    # 2) Split into whitelist vs not
    # ----------------------------
    # MTX_done rows keep the looked schema + whitelist flag
    mtx_done: List[List[str]] = []
    mtx_nd: List[List[str]] = []

    for r in primed:
        bc = r[0]
        if bc in wl_idx:
            mtx_done.append(r + ["Y"])
        else:
            mtx_nd.append(r + ["N"])

    done_counts = Counter([r[0] for r in mtx_done])
    log(f"[post] in-whitelist rows: {len(mtx_done)}")
    log(f"[post] not-in-whitelist rows: {len(mtx_nd)}")

    # ----------------------------
    # 3) Build MTX_sub and rescue (MTX_changed)
    # ----------------------------
    # Perl MTX_changed columns:
    # original_BC, V2..V12, whitelist, replaced_BC
    # where V2..V12 correspond to looked cols 1..11
    changed_header = [
        "original_BC",
        "V2",
        "V3",
        "V4",
        "V5",
        "V6",
        "V7",
        "V8",
        "V9",
        "V10",
        "V11",
        "V12",
        "whitelist",
        "replaced_BC",
    ]

    # Cache candidate lists per original barcode (Perl does unique + pre-calc)
    cand_cache: Dict[str, List[str]] = {}

    mtx_changed_rows: List[List[str]] = []
    rescued_rows_for_re: List[List[str]] = []

    for r in mtx_nd:
        ori_bc = r[0]
        bc_q = r[1]

        if ori_bc not in cand_cache:
            cand_cache[ori_bc] = hamm1_candidates(ori_bc, wl_idx)
        candidates = cand_cache[ori_bc]

        replaced = ""

        if len(candidates) == 0:
            replaced = "No_Hamm_1"
        else:
            # Build dat_n like Perl: (class, bc, qv, At, readN, priorP, p_edit, likelihood, postP)
            dat_n: List[dict] = []

            for i, cand_bc in enumerate(candidates):
                readN = int(done_counts.get(cand_bc, 0))
                if readN == 0:
                    qv = 0.0
                    at = first_diff_pos_1(ori_bc, cand_bc)
                else:
                    at = first_diff_pos_1(ori_bc, cand_bc)
                    qv_raw = bcq_at_pos(bc_q, at)
                    qv = min(33.0, qv_raw)
                dat_n.append({"i": i, "bc": cand_bc, "qv": qv, "At": at, "readN": readN})

            sum_readN = sum(d["readN"] for d in dat_n)
            for d in dat_n:
                priorP = (d["readN"] / sum_readN) if sum_readN > 0 else 0.0
                p_edit = 10 ** (-(d["qv"] / 10.0))
                likelihood = priorP * p_edit
                d["priorP"] = priorP
                d["p_edit"] = p_edit
                d["likelihood"] = likelihood

            sum_like = sum(d["likelihood"] for d in dat_n)
            for d in dat_n:
                d["postP"] = (d["likelihood"] / sum_like) if sum_like > 0 else 0.0

            max_post = max(d["postP"] for d in dat_n)
            max_rows = [d for d in dat_n if d["postP"] == max_post]

            # Perl special-case:
            # if sum_readN == 0 and Maxdat_n has >=2 rows => NO_in_SAVED
            if sum_readN == 0 and len(max_rows) >= 2:
                replaced = "NO_in_SAVED"
                # Perl keeps the first max row but doesn't use it later
            else:
                best = max_rows[0]
                if best["postP"] >= postp_cut:
                    replaced = best["bc"]
                else:
                    replaced = "Not_Sig"

                # Perl special-case: two-way exact tie at 0.5 => Not_Sig
                if len(max_rows) == 2 and abs(best["postP"] - 0.5) < 1e-12:
                    replaced = "Not_Sig"

        # Save MTX_changed row
        # r is looked cols + whitelist (N); we output original_BC + r[1..11] + whitelist + replaced
        out_row = [ori_bc] + r[1:12] + [r[12]] + [replaced]
        mtx_changed_rows.append(out_row)

        # Extract successfully rescued rows for MTX_RE
        if replaced not in {"NO_in_SAVED", "Not_Sig", "No_Hamm_1"}:
            # Perl: set V1 (barcode) to replaced_BC; keep whitelist as N.
            new_r = r[:]  # looked cols + whitelist
            new_r[0] = replaced
            rescued_rows_for_re.append(new_r)

    log(f"[post] MTX_changed rows: {len(mtx_changed_rows)}")
    log(f"[post] rescued rows used in MTX_RE: {len(rescued_rows_for_re)}")

    if keepouts:
        mtx_changed_path = os.path.join(outdir, f"{sample}.MTX_changed.txt")
        write_tsv(mtx_changed_path, changed_header, mtx_changed_rows)

    # ----------------------------
    # 4) Build MTX_RE rows (Perl-style columns)
    # ----------------------------
    # MTX_done and rescued are in the same schema: looked[0..11] + whitelist
    mtx_re_source = mtx_done + rescued_rows_for_re

    # Build rows for grouping/dedup in Perl MTX_RE.dedup schema
    # We'll build pre-dedup rows as dict-like lists with known positions.
    # Pre-dedup columns we need:
    # V1,V2,V3,V4,V5,mismatch.WT,mismatch.MUT,V8,V9,V10,BQ.in.WT,BQ.in.MUT,whitelist,BARCODE_UMI

    pre_rows: List[dict] = []
    for r in mtx_re_source:
        bc = r[0]
        umi = r[2]
        pre_rows.append(
            {
                "V1": bc,
                "V2": r[1],
                "V3": umi,
                "V4": r[3],
                "V5": r[4],
                "mismatch.WT": r[5],
                "mismatch.MUT": r[6],
                "V8": r[7],
                "V9": r[8],
                "V10": r[9],
                "BQ.in.WT": r[10],
                "BQ.in.MUT": r[11],
                "whitelist": r[12],
                "BARCODE_UMI": f"{bc}_{umi}",
            }
        )

    # Preserve Perl's unique() first-seen ordering of BARCODE_UMI
    seen_bu = set()
    bu_order: List[str] = []
    for pr in pre_rows:
        bu = pr["BARCODE_UMI"]
        if bu not in seen_bu:
            seen_bu.add(bu)
            bu_order.append(bu)

    # Group indices by BARCODE_UMI (preserving row order)
    bu_to_rows: Dict[str, List[dict]] = {}
    for pr in pre_rows:
        bu_to_rows.setdefault(pr["BARCODE_UMI"], []).append(pr)

    # ----------------------------
    # 5) Dedup per BARCODE_UMI (Perl logic)
    # ----------------------------

    def mismatch_call_per_read(mm_wt: int, mm_mut: int) -> Tuple[str, str, str]:
        """Perl MTX_RE_d mismatch assignment.

        Returns (wt_call, mut_call, call) where call is WT/MUT/amb.
        In this stage, amb is assigned when BOTH WT and MUT calls are present.
        """
        wt_call = "WT" if mm_wt <= wt_alw else ""
        mut_call = "MUT" if mm_mut <= wt_alw else ""

        call = "amb"
        if wt_call == "WT":
            call = "WT"
        if mut_call == "MUT":
            call = "MUT"
        if wt_call == "WT" and mut_call == "MUT":
            call = "amb"
        return wt_call, mut_call, call

    def best_quality_row(rows: List[dict]) -> dict:
        """Perl matrix_calc_best_quality on V2 (BC_Q): pick max sum(BC_Q)."""
        best = rows[0]
        best_sum = sum_bcq(best["V2"])
        for r in rows[1:]:
            s = sum_bcq(r["V2"])
            if s > best_sum:
                best = r
                best_sum = s
        return best

    dedup_header = [
        "V1",
        "V2",
        "V3",
        "V4",
        "V5",
        "mismatch.WT",
        "mismatch.MUT",
        "V8",
        "V9",
        "V10",
        "BQ.in.WT",
        "BQ.in.MUT",
        "whitelist",
        "BARCODE_UMI",
        "mismatch.call",
        "WT.inDups",
        "MUT.inDups",
        "amb.inDups",
    ]

    dedup_rows: List[List[str]] = []

    # Also keep a parsed representation for downstream MTX_MERGE building
    dedup_rows_dict: List[dict] = []

    for bu in bu_order:
        group = bu_to_rows[bu]

        # Assign mismatch calls for each read in the group
        for r in group:
            mm_wt = int(r["mismatch.WT"])
            mm_mut = int(r["mismatch.MUT"])
            wt_call, mut_call, call = mismatch_call_per_read(mm_wt, mm_mut)
            r["mismatch.WT.call"] = wt_call
            r["mismatch.MUT.call"] = mut_call
            r["mismatch.call"] = call

        wt_in = sum(1 for r in group if r["mismatch.call"] == "WT")
        mut_in = sum(1 for r in group if r["mismatch.call"] == "MUT")
        amb_in = sum(1 for r in group if r["mismatch.call"] == "amb")

        # Perl stores these counts in every row, then selects.
        for r in group:
            r["WT.inDups"] = str(wt_in)
            r["MUT.inDups"] = str(mut_in)
            r["amb.inDups"] = str(amb_in)

        # Selection logic (Perl-exact)
        if wt_in > mut_in:
            # IMPORTANT: Perl chooses min BQ.in.WT across *all* reads in MTX_RE_d
            min_bq = min(float(r["BQ.in.WT"]) for r in group)
            candidates = [r for r in group if float(r["BQ.in.WT"]) == min_bq]
        elif wt_in < mut_in:
            mut_reads = [r for r in group if r["mismatch.call"] == "MUT"]
            # Defensive: if none (shouldn't happen), fall back to all
            if not mut_reads:
                mut_reads = group
            min_bq = min(float(r["BQ.in.WT"]) for r in mut_reads)
            candidates = [r for r in mut_reads if float(r["BQ.in.WT"]) == min_bq]
        else:
            min_bq = min(float(r["BQ.in.WT"]) for r in group)
            candidates = [r for r in group if float(r["BQ.in.WT"]) == min_bq]

        best = candidates[0] if len(candidates) == 1 else best_quality_row(candidates)

        # Emit the chosen representative row in Perl MTX_RE.dedup schema
        out = [
            best["V1"],
            best["V2"],
            best["V3"],
            str(best["V4"]),
            str(best["V5"]),
            str(best["mismatch.WT"]),
            str(best["mismatch.MUT"]),
            str(best["V8"]),
            str(best["V9"]),
            str(best["V10"]),
            str(best["BQ.in.WT"]),
            str(best["BQ.in.MUT"]),
            best["whitelist"],
            best["BARCODE_UMI"],
            best["mismatch.call"],
            str(wt_in),
            str(mut_in),
            str(amb_in),
        ]
        dedup_rows.append(out)

        dedup_rows_dict.append(
            {
                "V1": best["V1"],
                "V2": best["V2"],
                "V3": best["V3"],
                "V4": int(best["V4"]),
                "V5": int(best["V5"]),
                "mismatch.WT": int(best["mismatch.WT"]),
                "mismatch.MUT": int(best["mismatch.MUT"]),
                "V8": best["V8"],
                "V9": best["V9"],
                "V10": best["V10"],
                "BQ.in.WT": best["BQ.in.WT"],
                "BQ.in.MUT": best["BQ.in.MUT"],
                "whitelist": best["whitelist"],
                "BARCODE_UMI": best["BARCODE_UMI"],
                "mismatch.call": best["mismatch.call"],
                "WT.inDups": wt_in,
                "MUT.inDups": mut_in,
                "amb.inDups": amb_in,
            }
        )

    log(f"[post] MTX_RE.dedup rows: {len(dedup_rows)}")

    if keepouts:
        dedup_path = os.path.join(outdir, f"{sample}.MTX_RE.dedup.txt")
        write_tsv(dedup_path, dedup_header, dedup_rows)

    # ----------------------------
    # 6) Build MTX_MERGE (Perl column order & names)
    # ----------------------------
    merge_header = [
        "BC",
        "whitelist",
        "UMI",
        "num.WT.in.dups",
        "num.MUT.in.dups",
        "num.amb.in.dups",
        "call.in.dups",
        "avg.base_error.R2",
        "avg.base_error.primer",
        "avg.base_error.shared",
        "avg.base_error.WT",
        "avg.base_error.MUT",
        "mismatch.primer",
        "mismatch.shared",
        "mismatch.WT",
        "mismatch.MUT",
    ]

    mtx_merge: List[dict] = []
    for d in dedup_rows_dict:
        mtx_merge.append(
            {
                "BC": d["V1"],
                "whitelist": d["whitelist"],
                "UMI": d["V3"],
                "num.WT.in.dups": str(d["WT.inDups"]),
                "num.MUT.in.dups": str(d["MUT.inDups"]),
                "num.amb.in.dups": str(d["amb.inDups"]),
                "call.in.dups": d["mismatch.call"],
                "avg.base_error.R2": str(d["V8"]),
                "avg.base_error.primer": str(d["V9"]),
                "avg.base_error.shared": str(d["V10"]),
                "avg.base_error.WT": str(d["BQ.in.WT"]),
                "avg.base_error.MUT": str(d["BQ.in.MUT"]),
                "mismatch.primer": str(d["V4"]),
                "mismatch.shared": str(d["V5"]),
                "mismatch.WT": str(d["mismatch.WT"]),
                "mismatch.MUT": str(d["mismatch.MUT"]),
            }
        )

    if keepouts:
        merge_path = os.path.join(outdir, f"{sample}.MTX_MERGE.txt")
        write_tsv(
            merge_path,
            merge_header,
            ([row[h] for h in merge_header] for row in mtx_merge),
        )

    # ----------------------------
    # 7) Summarize per BC (Perl summTable)
    # ----------------------------
    summ_header = merge_header + ["WT.calls", "MUT.calls", "amb.calls"]

    # Preserve BC order like Perl unique(): first-seen order in MTX_MERGE
    by_bc: Dict[str, List[dict]] = {}
    for row in mtx_merge:
        bc = row["BC"]
        if bc not in by_bc:
            by_bc[bc] = []
        by_bc[bc].append(row)

    summ_rows: List[List[str]] = []

    for bc, rows in by_bc.items():
        # Perl computes a temporary mismatch.call for counting from mismatch.WT/mismatch.MUT.
        # NOTE: In Perl cell-level amb_assign is "neither" case; MUT overwrites WT for both-case.
        cnt_wt = cnt_mut = cnt_amb = 0
        tmp_calls: List[str] = []
        for r in rows:
            mm_wt = int(r["mismatch.WT"])
            mm_mut = int(r["mismatch.MUT"])
            wt_call = "WT" if mm_wt <= wt_alw else ""
            mut_call = "MUT" if mm_mut <= wt_alw else ""

            call = ""
            if wt_call == "WT":
                call = "WT"
            if mut_call == "MUT":
                call = "MUT"  # overwrites WT if both
            if wt_call == "" and mut_call == "":
                call = "amb"

            tmp_calls.append(call)
            if call == "WT":
                cnt_wt += 1
            elif call == "MUT":
                cnt_mut += 1
            else:
                cnt_amb += 1

        # Build joined columns (exclude tmp_calls; Perl drops mismatch.call column from output)
        joined = []
        for h in merge_header:
            joined.append(";".join(r[h] for r in rows))

        # Apply dupcut filter like Perl
        # dup_WT + dup_MUT + dup_amb is computed from the joined in-dups columns
        def sum_semicol_int(s: str) -> int:
            total = 0
            for x in s.split(";"):
                x = x.strip()
                if not x:
                    continue
                try:
                    total += int(float(x))
                except ValueError:
                    continue
            return total

        dup_total = (
            sum_semicol_int(joined[3])
            + sum_semicol_int(joined[4])
            + sum_semicol_int(joined[5])
        )

        if dup_total >= dupcut:
            summ_rows.append(joined + [str(cnt_wt), str(cnt_mut), str(cnt_amb)])

    summ_path = os.path.join(outdir, f"{sample}.summTable.txt")
    write_tsv(summ_path, summ_header, summ_rows)

    log(f"[post] summTable rows (after dupcut): {len(summ_rows)}")
    return summ_path


# ----------------------------
# CLI
# ----------------------------

def main() -> None:
    ap = argparse.ArgumentParser(description="Perl-exact GoT python post-process (linear)")

    ap.add_argument("--run", required=True, choices=["linear"], help="Run mode (only 'linear' supported here)")
    ap.add_argument("--looked", required=True, help="Input <sample>.looked from Perl pre-process")
    ap.add_argument("--config", required=True, help="Config file")
    ap.add_argument("--whitelist", required=True, help="Whitelist file")
    ap.add_argument("--sample", required=True, help="Sample name (used in output filenames)")
    ap.add_argument("--outdir", required=True, help="Output directory")

    ap.add_argument("--mmtch", type=float, default=0.2, help="Mismatch ratio (Perl -m)")
    ap.add_argument("--postP", type=float, default=0.99, help="Posterior cutoff (Perl -p)")
    ap.add_argument("--dupcut", type=int, default=1, help="Duplicate cutoff for keeping cells")
    ap.add_argument("--keepouts", type=int, default=0, help="Write intermediate MTX files (1/0)")
    ap.add_argument("--verbose", type=int, default=0, help="Verbose logging (1/0)")

    args = ap.parse_args()

    primer_seq, general_seq, wt_seq = read_config_linear(args.config)

    primer_alw = perl_round_to_int(len(primer_seq) * args.mmtch)
    general_alw = perl_round_to_int(len(general_seq) * args.mmtch)
    wt_alw = perl_round_to_int(len(wt_seq) * args.mmtch)

    if args.verbose:
        print(f"[cfg] primer_len={len(primer_seq)} primer_alw={primer_alw}")
        print(f"[cfg] shared_len={len(general_seq)} shared_alw={general_alw}")
        print(f"[cfg] wt_len={len(wt_seq)} wt_alw={wt_alw}")

    looked_rows = read_looked_linear(args.looked)

    wl_idx = read_whitelist_with_order(args.whitelist)

    out = post_process_linear(
        looked_rows=looked_rows,
        wl_idx=wl_idx,
        primer_alw=primer_alw,
        general_alw=general_alw,
        wt_alw=wt_alw,
        postp_cut=float(args.postP),
        dupcut=int(args.dupcut),
        keepouts=int(args.keepouts),
        outdir=args.outdir,
        sample=args.sample,
        verbose=int(args.verbose),
    )

    if args.verbose:
        print(f"[done] wrote {out}")


if __name__ == "__main__":
    main()

